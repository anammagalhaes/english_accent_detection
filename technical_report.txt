
# Technical Report – English Accent Detection API 

## Objective

This project aims to detect English accents (e.g., American, British, Canadian, etc.) from speech extracted from video/audio input using Hugging Face models.

## Pipeline Overview

1. Accept input (via URL, local path, or upload).
2. Extract a 30-second audio segment using `ffmpeg`.
3. Load and classify the audio using a Hugging Face model (`HamzaSidhu786/speech-accent-detection`).
4. Return the most likely accent and confidence.

## Decisions

- The project was initially built with FastAPI and REST endpoints. Due to hardware constraints and deployment limitations, it was migrated to **Gradio + Hugging Face Spaces**, making the app easier to use and accessible via the web.
- Gradio was selected for its fast prototyping and seamless integration with Hugging Face Spaces.
- Audio is trimmed to 30 seconds to ensure faster inference and reduce memory usage.

## Hardware Constraints

Due to lack of local GPU resources, only CPU-compatible models were considered.
Advanced models such as:
- **Wav2Vec2 (Large)**
- **Whisper Large**

...were **not used** because they require GPU acceleration to run efficiently. Running them on CPU is either too slow or infeasible.

## Why Not Use Hugging Face GPU for Large Models?

Although Hugging Face Spaces **does offer free GPU access**, it has important **limitations**:
- GPUs may be in a queue or temporarily unavailable.
- Runtime is limited (e.g., 30–60 minutes).
- Memory constraints may crash heavier models like Whisper Large or Wav2Vec2 Large.

To ensure stability, a **lightweight CPU-compatible model** was chosen.

## Model Limitations

The model (`HamzaSidhu786/speech-accent-detection`) has known limitations:
- Can return generic predictions like `"English"` instead of `"British"` or `"American"`.
- Sometimes misclassifies due to class imbalance in training data (e.g., returning "Canadian" when it's not).
- More accurate performance would require fine-tuning on a balanced dataset.

## Endpoints / Input Modes

The Gradio application provides **three input methods**:
1. **URL input** – provide a link to a raw video/audio file.
2. **Local path** – paste the path to a file on the server (for local testing).
3. **File upload** – upload a video/audio file directly from your device.

All methods extract the audio and run the same accent detection pipeline.

## Suggested Improvements

- Use Whisper for transcription + keyword detection (hybrid accent detection).
- Train a balanced classifier for regional English accents.
- Add audio visualization and playback in the frontend.
- Deploy via custom Docker + GPU VM for advanced models.


